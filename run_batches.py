# TODO sort out source code in this project this is hacky
import sys

from helpers.model_load import get_model_output_paths, load_model
from helpers.save_images import calculate_output_folder
sys.path.extend([
    'src'
])
import json
import argparse
from lib.parameters import DeforumAnimArgs, Root, DeforumArgs
from pathlib import Path
from helpers.render import do_render, init_seed
from typing import Tuple, Any

# This is a hard-coded value that all the music keyframes are based on so changing it will break things
KEYFRAMES_PER_SECOND = 3

# Interpolation frame logic will generate 7 interpolation frames if depth is 3 to make 23
INTERPOLATION_RECURSION_DEPTH = 3

# Hard-coded value based on the hard-coded values above. 
# Changing this will result in a non-standard frame rate that then needs to be resampled to a standard
# frame rate for video playback (24, 25, 30, 60)
FPS = KEYFRAMES_PER_SECOND * 2^INTERPOLATION_RECURSION_DEPTH # = 24fps

def no_spaces(s:str):
    return s.replace(" ", "_")

def init_deforumargs(img:DeforumArgs, root:Root, motion:DeforumAnimArgs, combination_name: str, optional_initial_seed):
    # Additional properties of DeforumArgs that are visible in colab.
    # The DeforumArgs class is autogenerated from that, so we can't add them to the class definition.
    img.batch_name = combination_name

    # initial_seed might not be set
    init_seed(img, optional_initial_seed)

    img.W, img.H = map(lambda x: x - x % 64, (img.W, img.H))  # resize to integer multiple of 64
    img.n_samples = 1 # doesnt do anything
    img.precision = 'autocast' 
    img.C = 4
    img.f = 8

    img.prompt = ""
    img.timestring = ""
    img.init_latent = None
    img.init_sample = None
    img.init_sample_raw = None
    img.mask_sample = None
    img.init_c = None
    img.seed_internal = 0

    img.dynamic_threshold = None
    img.static_threshold = None   

    img.strength_0_no_init = True

    img.outdir = calculate_output_folder(img.seed, root.output_path, img.batch_name)
    print(f"### output folder: '{img.outdir}' using combination '{combination_name}'") # type: ignore

def create_movie_frames(img:DeforumArgs, motion:DeforumAnimArgs, root:Root, prompts:dict, general_style: str):
    do_render(img, motion, root, prompts, general_style)

def generate_combinations(properties, current_combination, index:int):
    if index == len(properties):
        yield current_combination
    else:
        prop_names, prop_values = properties[index]
        for value_set in prop_values:
            new_combination = current_combination.copy()
            if len(prop_names) == 1:  # Single property e.g. "img.sampler": ["dpm2", "heun",  "euler_ancestral"]
                prop_name = prop_names[0]
                if prop_name.startswith("img."):
                    img_prop_name = prop_name.split(".")[1]
                    if "img" not in new_combination:
                        new_combination["img"] = {}
                    new_combination["img"][img_prop_name] = value_set
                elif prop_name.startswith("motion."):
                    motion_prop_name = prop_name.split(".")[1]
                    if "motion" not in new_combination:
                        new_combination["motion"] = {}
                    new_combination["motion"][motion_prop_name] = value_set
                elif prop_name.startswith("root."):
                    root_prop_name = prop_name.split(".")[1]
                    if "root" not in new_combination:
                        new_combination["root"] = {}
                    new_combination["root"][root_prop_name] = value_set

            else:  # Multiple properties that only make sense together e.g. "img.H, img.W": [[512,512],[768,768]],
                img_dict = {}
                motion_dict = {}
                root_dict = {}
                for prop_name, value in zip(prop_names, value_set):
                    if prop_name.startswith("img."):
                        img_prop_name = prop_name.split(".")[1]
                        img_dict[img_prop_name] = value
                    elif prop_name.startswith("motion."):
                        motion_prop_name = prop_name.split(".")[1]
                        motion_dict[motion_prop_name] = value
                    elif prop_name.startswith("root."):
                        root_prop_name = prop_name.split(".")[1]
                        root_dict[root_prop_name] = value
                if img_dict:
                    if "img" not in new_combination:
                        new_combination["img"] = {}
                    new_combination["img"].update(img_dict)
                if motion_dict:
                    if "motion" not in new_combination:
                        new_combination["motion"] = {}
                    new_combination["motion"].update(motion_dict)
                if root_dict:
                    if "root" not in new_combination:
                        new_combination["root"] = {}
                    new_combination["root"].update(root_dict)
            yield from generate_combinations(properties, new_combination, index + 1)


_previous_model_checkpoint = None
_cached_model_tuple = None
def load_model_cached(root, load_on_run_all=True, check_sha256=True, map_location=None) -> Tuple[Any, Any]:
    global _previous_model_checkpoint
    global _cached_model_tuple

    model_checkpoint = root.model_checkpoint

    if model_checkpoint != _previous_model_checkpoint:
        print(f"### Cache: '{model_checkpoint}' not present, loading model")
        _cached_model_tuple = load_model(root, load_on_run_all=load_on_run_all, check_sha256=check_sha256, map_location=map_location)
        _previous_model_checkpoint = model_checkpoint
    # else:
    #     print(f"### Cache hit: using existing cached model '{model_checkpoint}'")

    return _cached_model_tuple

def init_rootargs(root:Root, composition_name:str ):
    # extend output path to include the name of the composition
    root.output_path = root.output_path + "/" + no_spaces(Path(composition_name).stem)
    # TODO unclear function name. Should be called "ensure exists"
    root.models_path, root.output_path = get_model_output_paths(root)

    print(f"### init_rootargs output folder: '{root.output_path}'") 
    # TODO model and device are not input parameters in the original ipynb so didn't propagate to Root class in my export script
    root.model, root.device = load_model_cached(root, load_on_run_all=True, check_sha256=True, map_location=root.map_location)
    print(f"loaded model {root.model_checkpoint} on device {root.device}") # type: ignore

def extract_properties(combinations, dictionary_name):
    extracted_properties = []
    for keys, values in combinations.items():
        key_list = keys.split(",")
        prop_names = [key.strip() for key in key_list]
        if dictionary_name == "img":
            prop_names = [prop_name for prop_name in prop_names if prop_name.startswith("img.")]
        elif dictionary_name == "motion":
            prop_names = [prop_name for prop_name in prop_names if prop_name.startswith("motion.")]
        elif dictionary_name == "root":
            prop_names = [prop_name for prop_name in prop_names if prop_name.startswith("root.")]
        if prop_names:
            extracted_properties.append((prop_names, values))
    if not extracted_properties:
        print(f"No {dictionary_name} properties found")
    else:
        print(f"Extracted {dictionary_name} properties: {extracted_properties}")
    return extracted_properties

def generate_combination_name(root_combination, motion_combination, img_combination):
    root = str(root_combination.get('root', ''))
    motion = str(motion_combination.get('motion', ''))
    img = str(img_combination.get('img', ''))

    strings = [root, motion, img]
    filtered_strings = list(filter(lambda s: len(s) > 0, strings))

    raw_name = "&".join(filtered_strings)

    # Remove single quotes, curly braces, and spaces using list comprehension
    # so you get something like this "root:model_checkpoint:Protogen_V2.2.ckpt__"
    result =  "".join([c for c in raw_name if c not in "'.{} "])
    result = result.replace(":", "=")
    return result

def calculate_max_frames(duration_in_seconds:float, num_keyframes_override:int) -> int:
    if num_keyframes_override is not None:
        return num_keyframes_override
    else:
        EXTRA_END_FRAMES = 10
        # TODO the composition duration is inside the metadata.json file
        # we need to load it
        # we then also need to extract the fps and the recursion depth to calculate fps
        # once we have file duration and fps we can calculate the max frames
        return int(duration_in_seconds * FPS) + EXTRA_END_FRAMES


parser = argparse.ArgumentParser()
parser.add_argument('--input', type=str, required=True, help='Path to the input JSON file')
parser.add_argument("--mp3-dir", default="music", help="Location of MP3 files in config file.")
# add a flag to indicate whether to run the rendering or not
parser.add_argument("--dry-run", action="store_true", help="If set, don't render video")
parser.add_argument("--initial-seed", type=int, nargs='?', default=None, help="Override random seed generation with a reproduceable starting point every run")

args = parser.parse_args()
dry_run = args.dry_run
input_file = args.input
initial_seed = args.initial_seed

with open(input_file, "r") as file:
    batch_settings = json.load(file)

# pull data from the batch settings file
compositions = batch_settings["compositions"]
combinations = batch_settings["combinations"]

# we may want to restrict the number of frames from a specific item in the batch to do sampling
# sometimes we just want a fixed clip length for all the items in the batch
num_keyframes_override = batch_settings.get("num_keyframes_override", None)

print(f"Combinations: {combinations}")
img_properties = extract_properties(combinations, "img")
motion_properties = extract_properties(combinations, "motion")
root_properties = extract_properties(combinations, "root")

img_combinations = [{} for _ in range(len(img_properties))]
motion_combinations = [{} for _ in range(len(motion_properties))]
root_combinations = [{} for _ in range(len(root_properties))]

mp3_dir = args.mp3_dir
count = 0
for composition_file_name in compositions:
    # pull metadata from analysis file
    music_metadata_file = mp3_dir / Path(Path(composition_file_name).stem + "-analysis/full-metadata.json")
    music_metadata = music_metadata_file.read_text()
    # read analysis data into a json object 
    music_metadata = json.loads(music_metadata)

    duration = music_metadata['duration']
    zoom = music_metadata['animation']['keyframe_zoom_animations']
    # style is appended to the end of every prompt to present a consistent style
    style = music_metadata['style']
    prompts = {}
    for key, value in music_metadata['keyframes'].items():
        prompts[int(key)] = value['prompt']

    print(f'== {composition_file_name}:')
    print(f'zoom: "{zoom[:60]}..."')
    print(f'prompts:\n{json.dumps(prompts,indent=2)}\n\n')

    for img_combination in generate_combinations(img_properties, {}, 0):
        for motion_combination in generate_combinations(motion_properties, {}, 0):
            for root_combination in generate_combinations(root_properties, {}, 0):
                root_instance = Root()
                if "root" in root_combination:
                    for prop_name, value in root_combination["root"].items():
                        setattr(root_instance, prop_name, value)
                init_rootargs(root_instance, composition_file_name)
                
                motion_instance = DeforumAnimArgs()
                if "motion" in motion_combination:
                    for prop_name, value in motion_combination["motion"].items():
                        setattr(motion_instance, prop_name, value)
                motion_instance.max_frames = calculate_max_frames(duration, num_keyframes_override)

                img_instance = DeforumArgs()
                if "img" in img_combination:
                    for prop_name, value in img_combination["img"].items():
                        setattr(img_instance, prop_name, value)
                conbination_name = generate_combination_name(root_combination, motion_combination, img_combination)

                init_deforumargs(img_instance, root_instance, motion_instance, conbination_name, initial_seed)
                
                # we don't generate the same combination twice even with separate runs
                if Path(img_instance.outdir).exists(): # type: ignore
                    print(f"Skipping {composition_file_name} with combination '{conbination_name}' because it already exists")
                else:
                    count += 1
                    if args.dry_run:
                        print(f"Dry run: skipping rendering of {composition_file_name} with combination {conbination_name} saved in {img_instance.outdir}")   
                    else:
                        Path(img_instance.outdir).mkdir(parents=True) # type: ignore
                        create_movie_frames(img_instance, motion_instance, root_instance, prompts, style)

print(f"{count} combinations generated")
